"""Generate individual posts from news articles for @ai_dlya_doma channel."""

import json
import os
import re
from dataclasses import dataclass
from enum import Enum
from typing import Dict, List, Optional, Tuple

from anthropic import (
    Anthropic,
    APIConnectionError,
    APITimeoutError,
    RateLimitError,
)
from tenacity import (
    retry,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential,
)

from logger import get_logger

logger = get_logger("news_bot.post_generator")


def parse_classifier_response(response_text: str) -> dict:
    """
    Parse classifier response with error handling.
    Returns default response if LLM returned invalid JSON.
    """
    DEFAULT_RESPONSE = {
        "relevant": False,
        "confidence": 0,
        "category": "parse_error",
        "format": "ai_tool",
        "reason": "Failed to parse LLM response",
        "needs_review": True,
        "url_check_needed": True,
    }

    try:
        # Remove markdown code blocks if present
        cleaned = re.sub(r"^```json\s*", "", response_text.strip())
        cleaned = re.sub(r"\s*```$", "", cleaned)

        # Try to find JSON in text
        json_match = re.search(r"\{[^{}]*\}", cleaned, re.DOTALL)
        if json_match:
            cleaned = json_match.group()

        data = json.loads(cleaned)

        # Validate required fields
        if "relevant" not in data or "confidence" not in data:
            data = DEFAULT_RESPONSE.copy()
            data["reason"] = "Missing required fields"
            return data

        # Normalize confidence to 0-100
        data["confidence"] = max(0, min(100, int(data.get("confidence", 0))))

        # Defaults for optional fields
        data.setdefault("category", "unknown")
        data.setdefault("format", "ai_tool")
        data.setdefault("reason", "")
        data.setdefault("needs_review", data["confidence"] < 70)
        data.setdefault("url_check_needed", False)

        return data

    except (json.JSONDecodeError, TypeError, ValueError) as e:
        response = DEFAULT_RESPONSE.copy()
        response["reason"] = f"JSON parse error: {str(e)[:50]}"
        return response


def validate_telegram_html(text: str) -> str:
    """
    Validate and fix common HTML issues for Telegram.

    Telegram supports: <b>, <i>, <u>, <s>, <code>, <pre>, <a href="">
    """
    if not text:
        return text

    # Allowed Telegram HTML tags
    allowed_tags = ['b', 'i', 'u', 's', 'code', 'pre', 'a']

    # Count open and close tags
    for tag in allowed_tags:
        open_count = len(re.findall(rf'<{tag}[^>]*>', text, re.IGNORECASE))
        close_count = len(re.findall(rf'</{tag}>', text, re.IGNORECASE))

        # If imbalanced, try to fix or remove
        if open_count != close_count:
            logger.warning(f"HTML tag <{tag}> imbalanced: {open_count} open, {close_count} close")
            # Remove all instances of this tag if imbalanced
            text = re.sub(rf'<{tag}[^>]*>', '', text, flags=re.IGNORECASE)
            text = re.sub(rf'</{tag}>', '', text, flags=re.IGNORECASE)

    # Fix common LLM mistakes with <a> tags
    # Fix: <a href = "url"> ‚Üí <a href="url">
    text = re.sub(r'<a\s+href\s*=\s*["\']([^"\']+)["\']>', r'<a href="\1">', text)

    # Fix: missing quotes around href
    text = re.sub(r'<a\s+href=([^"\'\s>]+)>', r'<a href="\1">', text)

    # Remove any unsupported HTML tags
    text = re.sub(r'<(?!/?(?:b|i|u|s|code|pre|a)[^>]*>)[^>]+>', '', text)

    return text.strip()


class PostFormat(Enum):
    """Types of posts for the channel."""
    AI_TOOL = "ai_tool"          # AI-–Ω–∞—Ö–æ–¥–∫–∞ –¥–Ω—è
    QUICK_TIP = "quick_tip"      # –ë—ã—Å—Ç—Ä—ã–π —Å–æ–≤–µ—Ç
    PROMPT_DAY = "prompt_day"    # –ü—Ä–æ–º—Ç –¥–Ω—è
    COMPARISON = "comparison"    # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ
    CHECKLIST = "checklist"      # –ß–µ–∫-–ª–∏—Å—Ç


@dataclass
class GeneratedPost:
    """A generated post ready for publication."""
    text: str
    format: PostFormat
    article_url: str
    article_title: str
    image_prompt: Optional[str] = None
    image_url: Optional[str] = None  # OG/RSS image URL from article


class PostGenerator:
    """Generate beautiful posts for Telegram channel."""

    def __init__(self, api_key: str = None):
        """Initialize with Anthropic API."""
        self.api_key = api_key or os.getenv("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found")

        self.client = Anthropic(api_key=self.api_key)
        self.haiku_model = "claude-3-haiku-20240307"
        self.sonnet_model = "claude-sonnet-4-20250514"

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=2, min=4, max=60),
        retry=retry_if_exception_type(
            (RateLimitError, APIConnectionError, APITimeoutError)
        ),
        before_sleep=lambda retry_state: logger.warning(
            f"Claude API retry {retry_state.attempt_number}: "
            f"{retry_state.outcome.exception()}"
        ),
    )
    def _call_api(self, model: str, prompt: str, max_tokens: int = 1000) -> str:
        """Call Claude API with retry."""
        message = self.client.messages.create(
            model=model,
            max_tokens=max_tokens,
            temperature=0.7,
            messages=[{"role": "user", "content": prompt}],
        )
        return message.content[0].text

    def classify_article(self, article: Dict) -> Optional[Dict]:
        """
        Classify if article is relevant for the channel.
        Uses Haiku for cost efficiency.

        Returns:
            Dict with {relevant: bool, confidence: int, category: str, format: str,
                       reason: str, needs_review: bool, url_check_needed: bool}
            or None if error
        """
        title = article.get("title", "")
        description = article.get("summary", "")[:500]

        prompt = f"""–¢—ã ‚Äî –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è Telegram-–∫–∞–Ω–∞–ª–∞ "AI –¥–ª—è –¥–æ–º–∞".

–¶–ï–õ–ï–í–ê–Ø –ê–£–î–ò–¢–û–†–ò–Ø:
- –í—Å–µ, –∫—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è AI –∏ —Ö–æ—á–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –≤ –∂–∏–∑–Ω–∏
- –ù–µ —Ç–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∞—Ä–∏ ‚Äî –æ–±—ã—á–Ω—ã–µ –ª—é–¥–∏ —Ç–æ–∂–µ
- –ò–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç: —á—Ç–æ –Ω–æ–≤–æ–≥–æ –≤ –º–∏—Ä–µ AI, –∫–∞–∫–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ø–æ—è–≤–∏–ª–∏—Å—å, —á—Ç–æ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å

–í–ö–õ–Æ–ß–ê–¢–¨ (relevant: true):
- AI-–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –ª—é–±–æ–≥–æ —Ç–∏–ø–∞ (ChatGPT, Claude, Midjourney, Runway –∏ –¥—Ä.)
- –ù–æ–≤–æ—Å—Ç–∏ AI-–∫–æ–º–ø–∞–Ω–∏–π (OpenAI, Anthropic, Google, Meta, Microsoft)
- –û–±–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π (GPT-5, Claude 4, Gemini 2, Llama 4 –∏ –¥—Ä.)
- –¢—Ä–µ–Ω–¥—ã –≤ AI: —á—Ç–æ –º–µ–Ω—è–µ—Ç—Å—è, –∫—É–¥–∞ –¥–≤–∏–∂–µ—Ç—Å—è –∏–Ω–¥—É—Å—Ç—Ä–∏—è
- –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è AI (–∫–µ–π—Å—ã, –ø—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
- –°—Ä–∞–≤–Ω–µ–Ω–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
- AI –≤ –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω–æ–π –∂–∏–∑–Ω–∏
- –ù–æ–≤—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–µ—Ä–≤–∏—Å–∞—Ö

–ò–°–ö–õ–Æ–ß–ê–¢–¨ (relevant: false):
- –ß–∏—Å—Ç–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è (API docs, SDK reference)
- –ö–æ–¥, —Ç—É—Ç–æ—Ä–∏–∞–ª—ã –¥–ª—è –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç–æ–≤
- –¢–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ (–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ –±–µ–∑ –ø—Ä–æ–¥—É–∫—Ç–∞/—Ñ—É–Ω–∫—Ü–∏–∏)
- –°—Ç–∞—Ç—å–∏ —Å—Ç–∞—Ä—à–µ 7 –¥–Ω–µ–π (–ø—Ä–æ–≤–µ—Ä—å –¥–∞—Ç—É –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞)
- –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞, NFT, blockchain (–µ—Å–ª–∏ –Ω–µ —Å–≤—è–∑–∞–Ω–æ —Å AI)
- –ù–∞—É—á–Ω—ã–µ —Å—Ç–∞—Ç—å–∏ –±–µ–∑ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–ª—å–∑—ã
- –í–∞–∫–∞–Ω—Å–∏–∏, –Ω–∞–π–º

EDGE-CASES:
- "OpenAI raises $10B" ‚Üí –ò–°–ö–õ–Æ–ß–ò–¢–¨ (—Ç–æ–ª—å–∫–æ —Ñ–∏–Ω–∞–Ω—Å—ã)
- "OpenAI launches new feature" ‚Üí –í–ö–õ–Æ–ß–ò–¢–¨
- "How to build AI agent" (–¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤) ‚Üí –ò–°–ö–õ–Æ–ß–ò–¢–¨
- "Best AI tools for 2025" ‚Üí –í–ö–õ–Æ–ß–ò–¢–¨
- "New Claude model" ‚Üí –í–ö–õ–Æ–ß–ò–¢–¨
- –ü—É—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ ‚Üí —Å–Ω–∏–∑—å confidence –Ω–∞ 20

FALLBACK:
- –ù–µ —É–≤–µ—Ä–µ–Ω ‚Üí confidence < 70
- –ù–∞ –≥—Ä–∞–Ω–∏ ‚Üí relevant: true, confidence: 55-65, needs_review: true
- –ù–µ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Üí category: "news"

–°–¢–ê–¢–¨–Ø:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}
–ò—Å—Ç–æ—á–Ω–∏–∫: {article.get('source', '')}
–û–ø–∏—Å–∞–Ω–∏–µ: {description}
–°—Å—ã–ª–∫–∞: {article.get('link', '')}

–û–ø—Ä–µ–¥–µ–ª–∏:
1. –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–∞ –ª–∏ —Å—Ç–∞—Ç—å—è?
2. –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å (0-100)
3. –ö–∞—Ç–µ–≥–æ—Ä–∏—è (tool/news/update/trend/comparison/tip)
4. –ü—Ä–∏—á–∏–Ω–∞ (–∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º)

–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON –±–µ–∑ markdown:
{{"relevant": true/false, "confidence": 0-100, "category": "...", "reason": "...", "needs_review": false, "url_check_needed": false}}"""

        try:
            response = self._call_api(self.haiku_model, prompt, max_tokens=250)
            result = parse_classifier_response(response)

            # Log classification result
            if result.get("needs_review"):
                logger.info(
                    f"Needs review: {title[:50]}... "
                    f"(confidence: {result.get('confidence')}, reason: {result.get('reason')})"
                )

            return result
        except Exception as e:
            logger.error(f"Error classifying article: {e}")
            return None

    def generate_post(self, article: Dict, post_format: PostFormat) -> Optional[GeneratedPost]:
        """
        Generate a post from article in specified format.
        Uses Sonnet for quality.
        """
        format_templates = {
            PostFormat.AI_TOOL: self._get_ai_tool_prompt(article),
            PostFormat.QUICK_TIP: self._get_quick_tip_prompt(article),
            PostFormat.PROMPT_DAY: self._get_prompt_day_prompt(article),
        }

        prompt = format_templates.get(post_format)
        if not prompt:
            logger.error(f"Unknown format: {post_format}")
            return None

        try:
            response = self._call_api(self.sonnet_model, prompt, max_tokens=800)

            # Parse response (expecting JSON with text and image_prompt)
            try:
                # Clean markdown code blocks if present
                cleaned = response.strip()
                cleaned = re.sub(r"^```json\s*", "", cleaned, flags=re.IGNORECASE)
                cleaned = re.sub(r"^```\s*", "", cleaned)
                cleaned = re.sub(r"\s*```$", "", cleaned)

                # Try to find JSON object in response with nested braces support
                json_match = re.search(r'\{.*?"text"\s*:\s*".*?\}', cleaned, re.DOTALL)
                if json_match:
                    # Extract the full JSON object including nested content
                    brace_count = 0
                    start_idx = json_match.start()
                    for i, char in enumerate(cleaned[start_idx:], start=start_idx):
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                cleaned = cleaned[start_idx:i+1]
                                break

                data = json.loads(cleaned)
                text = data.get("text")
                image_prompt = data.get("image_prompt")

                # Fallback if text extraction failed
                if not text:
                    logger.warning("JSON parsed but 'text' field empty, using raw response")
                    text = response

            except (json.JSONDecodeError, TypeError, ValueError) as e:
                logger.warning(f"Failed to parse post JSON: {e}, using raw response")
                text = response
                image_prompt = None

            # Validate and fix HTML before returning
            text = validate_telegram_html(text)

            return GeneratedPost(
                text=text,
                format=post_format,
                article_url=article.get("link", ""),
                article_title=article.get("title", ""),
                image_prompt=image_prompt,
                image_url=article.get("image_url"),  # OG/RSS image from article
            )
        except Exception as e:
            logger.error(f"Error generating post: {e}")
            return None

    def _get_ai_tool_prompt(self, article: Dict) -> str:
        """Prompt for AI-–Ω–∞—Ö–æ–¥–∫–∞ –¥–Ω—è format."""
        article_link = article.get('link', '')
        return f"""–¢—ã ‚Äî –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ "AI –¥–ª—è –º–∞–º—ã".

–¶–ï–õ–ï–í–ê–Ø –ê–£–î–ò–¢–û–†–ò–Ø: –∂–µ–Ω—â–∏–Ω—ã 25-45, –ù–ï —Ç–µ—Ö–Ω–∞—Ä–∏. –•–æ—Ç—è—Ç —É–ø—Ä–æ—Å—Ç–∏—Ç—å –±—ã—Ç —á–µ—Ä–µ–∑ AI.

–°–¢–ò–õ–¨:
- –î—Ä—É–∂–µ–ª—é–±–Ω—ã–π, –∫–∞–∫ —Å–æ–≤–µ—Ç –æ—Ç –ø–æ–¥—Ä—É–≥–∏
- –ë–ï–ó —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞
- –≠–º–æ–¥–∑–∏: 1-2 —à—Ç—É–∫–∏, –ø–æ –¥–µ–ª—É
- –û–±—Ä–∞—â–µ–Ω–∏–µ –Ω–∞ "—Ç—ã"
- –ö–æ—Ä–æ—Ç–∫–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
- –ú–∞–∫—Å–∏–º—É–º 350 —Å–∏–º–≤–æ–ª–æ–≤

–ê–ù–¢–ò-–ü–ê–¢–¢–ï–†–ù–´ (–Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π):
- "–ù–µ–π—Ä–æ—Å–µ—Ç—å" ‚Üí –∑–∞–º–µ–Ω—è–π –Ω–∞ "AI"
- "–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π", "—É–Ω–∏–∫–∞–ª—å–Ω—ã–π", "–ª—É—á—à–∏–π" ‚Üí —É–±–∏—Ä–∞–π
- –ù–∞—á–∞–ª–æ —Å "–ü—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ–º..." –∏–ª–∏ "–í—Å—Ç—Ä–µ—á–∞–π—Ç–µ..." ‚Üí –Ω–∞—á–∏–Ω–∞–π —Å —Å—É—Ç–∏
- "–¶–µ–Ω–∞: —É—Ç–æ—á–Ω—è–π –Ω–∞ —Å–∞–π—Ç–µ" ‚Üí –í–û–û–ë–©–ï –ù–ï –ü–ò–®–ò –µ—Å–ª–∏ –Ω–µ—Ç —Ü–µ–Ω—ã
- –†–µ–∞–∫—Ü–∏–∏ —Ç–∏–ø–∞ "üî• ‚Äî —É–∂–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞" ‚Üí –ù–ï –î–û–ë–ê–í–õ–Ø–ô
- –ì–û–õ–´–ï URL ‚Äî –ù–ò–ö–û–ì–î–ê –Ω–µ –ø–∏—à–∏ URL –∫–∞–∫ –µ—Å—Ç—å, —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ HTML-—Å—Å—ã–ª–∫—É

–°–¢–ê–¢–¨–Ø –î–õ–Ø –û–ë–†–ê–ë–û–¢–ö–ò:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.get('title', '')}
–û–ø–∏—Å–∞–Ω–∏–µ: {article.get('summary', '')[:500]}
–°—Å—ã–ª–∫–∞: {article_link}

–§–û–†–ú–ê–¢ –ü–û–°–¢–ê (HTML-—Ä–∞–∑–º–µ—Ç–∫–∞ –¥–ª—è Telegram):
```
ü§ñ <b>[–ù–∞–∑–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞]</b>

[–ß—Ç–æ –¥–µ–ª–∞–µ—Ç ‚Äî 1-2 —Ñ—Ä–∞–∑—ã]

[–ó–∞—á–µ–º –Ω—É–∂–Ω–æ —Ç–µ–±–µ ‚Äî 1 —Ñ—Ä–∞–∑–∞]

[–¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –¢–û–ß–ù–û –∏–∑–≤–µ—Å—Ç–Ω–∞ —Ü–µ–Ω–∞: üí∞ –ë–µ—Å–ø–ª–∞—Ç–Ω–æ / $X/–º–µ—Å]

üëâ <a href="{article_link}">–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å</a>
```

–í–ê–ñ–ù–û –û –°–°–´–õ–ö–ê–•:
- –ù–ò–ö–û–ì–î–ê –Ω–µ –ø–∏—à–∏ –≥–æ–ª—ã–π URL
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û HTML-—Ñ–æ—Ä–º–∞—Ç: <a href="URL">—Ç–µ–∫—Å—Ç</a>
- –¢–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏: "–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å", "–°–º–æ—Ç—Ä–µ—Ç—å", "–û—Ç–∫—Ä—ã—Ç—å"
- URL –±–µ—Ä–∏ –∏–∑ —Å—Ç–∞—Ç—å–∏: {article_link}

–û—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON –±–µ–∑ markdown –±–ª–æ–∫–æ–≤:
{{"text": "–≥–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç —Å HTML-—Ä–∞–∑–º–µ—Ç–∫–æ–π", "image_prompt": "DALL-E prompt in English, flat design, pastel colors, 40 words max"}}"""

    def _get_quick_tip_prompt(self, article: Dict) -> str:
        """Prompt for –ë—ã—Å—Ç—Ä—ã–π —Å–æ–≤–µ—Ç format."""
        article_link = article.get('link', '')
        return f"""–¢—ã ‚Äî –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ "AI –¥–ª—è –º–∞–º—ã".

–¶–ï–õ–ï–í–ê–Ø –ê–£–î–ò–¢–û–†–ò–Ø: –∂–µ–Ω—â–∏–Ω—ã 25-45, –ù–ï —Ç–µ—Ö–Ω–∞—Ä–∏.

–°–¢–ò–õ–¨: –∫–æ—Ä–æ—Ç–∫–∏–π —Å–æ–≤–µ—Ç, 200-250 —Å–∏–º–≤–æ–ª–æ–≤, –±–µ–∑ –≤–æ–¥—ã

–°–¢–ê–¢–¨–Ø:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.get('title', '')}
–û–ø–∏—Å–∞–Ω–∏–µ: {article.get('summary', '')[:500]}
–°—Å—ã–ª–∫–∞: {article_link}

–§–û–†–ú–ê–¢ (HTML-—Ä–∞–∑–º–µ—Ç–∫–∞ –¥–ª—è Telegram):
```
‚ö° <b>[–ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–æ–≤–µ—Ç–∞]</b>

[–ß—Ç–æ —Å–¥–µ–ª–∞—Ç—å ‚Äî 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

‚ú® [–†–µ–∑—É–ª—å—Ç–∞—Ç ‚Äî —á—Ç–æ –ø–æ–ª—É—á–∏—à—å]

üëâ <a href="{article_link}">–ü–æ–¥—Ä–æ–±–Ω–µ–µ</a>
```

–í–ê–ñ–ù–û –û –°–°–´–õ–ö–ê–•:
- –ù–ò–ö–û–ì–î–ê –Ω–µ –ø–∏—à–∏ –≥–æ–ª—ã–π URL
- –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û: <a href="URL">—Ç–µ–∫—Å—Ç</a>

–û—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û JSON –±–µ–∑ markdown:
{{"text": "–≥–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç —Å HTML", "image_prompt": "DALL-E prompt in English, flat design, pastel colors, 40 words"}}"""

    def _get_prompt_day_prompt(self, article: Dict) -> str:
        """Prompt for –ü—Ä–æ–º—Ç –¥–Ω—è format."""
        return f"""–¢—ã ‚Äî –∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä Telegram-–∫–∞–Ω–∞–ª–∞ "AI –¥–ª—è –º–∞–º—ã".

–¶–ï–õ–ï–í–ê–Ø –ê–£–î–ò–¢–û–†–ò–Ø: –∂–µ–Ω—â–∏–Ω—ã 25-45, –ù–ï —Ç–µ—Ö–Ω–∞—Ä–∏.

–°–¢–ò–õ–¨: –∫–æ—Ä–æ—Ç–∫–∏–π –ø–æ–ª–µ–∑–Ω—ã–π –ø—Ä–æ–º—Ç, 300-350 —Å–∏–º–≤–æ–ª–æ–≤

–°–¢–ê–¢–¨–Ø:
–ó–∞–≥–æ–ª–æ–≤–æ–∫: {article.get('title', '')}
–û–ø–∏—Å–∞–Ω–∏–µ: {article.get('summary', '')[:500]}

–§–û–†–ú–ê–¢ (HTML-—Ä–∞–∑–º–µ—Ç–∫–∞ –¥–ª—è Telegram):
```
üéØ <b>[–¢–µ–º–∞ –ø—Ä–æ–º—Ç–∞]</b>

<b>–ü—Ä–æ–º—Ç:</b>
<code>[–≥–æ—Ç–æ–≤—ã–π –ø—Ä–æ–º—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –º–æ–∂–Ω–æ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å]</code>

‚ú® [–ß—Ç–æ –ø–æ–ª—É—á–∏—à—å ‚Äî 1 —Ñ—Ä–∞–∑–∞]
```

–í–ê–ñ–ù–û:
- –ü—Ä–æ–º—Ç –æ–±–µ—Ä–Ω–∏ –≤ <code></code> ‚Äî —Ç–∞–∫ —É–¥–æ–±–Ω–æ –∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å
- –ó–∞–≥–æ–ª–æ–≤–∫–∏ –≤ <b></b>

–û—Ç–≤–µ—Ç –¢–û–õ–¨–ö–û JSON –±–µ–∑ markdown:
{{"text": "–≥–æ—Ç–æ–≤—ã–π –ø–æ—Å—Ç —Å HTML", "image_prompt": "DALL-E prompt in English, flat design, pastel colors, 40 words"}}"""

    def generate_image_prompt(self, post: GeneratedPost) -> str:
        """
        Generate DALL-E prompt for post image.
        Uses Haiku for cost efficiency.
        """
        if post.image_prompt:
            return post.image_prompt

        prompt = f"""Create a DALL-E 3 image prompt for this Telegram post:

POST:
{post.text[:300]}

STYLE REQUIREMENTS:
- Flat design with soft gradients
- Pastel colors: light blue, pink, mint, lavender
- Minimalist icons
- Isometric perspective
- NO text on image
- NO people faces
- Cozy, friendly feeling
- Modern, clean look

Format: 1024x1024, English, 50-80 words.

Respond with ONLY the prompt, no explanations."""

        try:
            return self._call_api(self.haiku_model, prompt, max_tokens=150)
        except Exception as e:
            logger.error(f"Error generating image prompt: {e}")
            return "Flat design illustration, pastel colors, minimalist icons, cozy modern aesthetic, soft gradients, no text"

    def filter_and_rank_articles(
        self, articles: List[Dict], max_posts: int = 5
    ) -> List[tuple]:
        """
        Filter relevant articles and rank by confidence.

        Returns:
            List of (article, classification) tuples, sorted by confidence
        """
        classified = []

        for article in articles:
            result = self.classify_article(article)
            if result and result.get("relevant") and result.get("confidence", 0) >= 45:
                classified.append((article, result))
                logger.info(
                    f"Relevant: {article.get('title', '')[:50]}... "
                    f"(confidence: {result.get('confidence')})"
                )

        # Sort by confidence, take top N
        classified.sort(key=lambda x: x[1].get("confidence", 0), reverse=True)
        return classified[:max_posts]

    def generate_daily_posts(
        self, articles: List[Dict], count: int = 5
    ) -> List[GeneratedPost]:
        """
        Generate posts for the day from articles.

        Args:
            articles: List of news articles
            count: Number of posts to generate

        Returns:
            List of GeneratedPost objects
        """
        logger.info(f"Generating {count} posts from {len(articles)} articles")

        # Filter and rank articles
        ranked = self.filter_and_rank_articles(articles, max_posts=count)

        if not ranked:
            logger.warning("No relevant articles found")
            return []

        posts = []
        for article, classification in ranked:
            format_str = classification.get("format", "ai_tool")
            try:
                post_format = PostFormat(format_str)
            except ValueError:
                post_format = PostFormat.AI_TOOL

            post = self.generate_post(article, post_format)
            if post:
                # Generate image prompt if not present
                if not post.image_prompt:
                    post.image_prompt = self.generate_image_prompt(post)
                posts.append(post)
                logger.info(f"Generated post: {post.format.value}")

        return posts


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()

    generator = PostGenerator()

    # Test with dummy article
    test_article = {
        "title": "Canva launches AI photo editor for Instagram",
        "source": "TechCrunch",
        "summary": "Canva announced a new AI-powered photo editor that can automatically enhance photos, remove backgrounds, and suggest Instagram-ready filters. The tool is free for basic use.",
        "link": "https://example.com/canva-ai",
    }

    print("Testing classification...")
    result = generator.classify_article(test_article)
    print(f"Classification: {result}")

    if result and result.get("relevant"):
        print("\nGenerating post...")
        post = generator.generate_post(test_article, PostFormat.AI_TOOL)
        if post:
            print(f"\n{post.text}")
            print(f"\nImage prompt: {post.image_prompt}")
